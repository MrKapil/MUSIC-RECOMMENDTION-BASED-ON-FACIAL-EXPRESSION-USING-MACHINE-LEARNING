# MUSIC-RECOMMENDTION-BASED-ON-FACIAL-EXPRESSION-USING-MACHINE-LEARNING
3rd year Project


This project proposes the development of a personalized music recommendation system based on facial expressions using machine learning algorithms. The system aims to accurately predict emotional states such as happiness, sadness, anger, and fear based on computer vision analysis of facial expressions, and music feature analysis of tempo, key, and mood. The predicted emotional states will be used to recommend personalized music that is likely to evoke a positive emotional response in the user. The system will be trained and tested on labeled datasets of facial expressions and corresponding emotional states, as well as music datasets with corresponding emotional features. The performance of the system will be evaluated using metrics such as precision, recall, and F1-score, and user studies will be conducted to validate the effectiveness of the system in improving mood and reducing symptoms of emotional distress. The potential therapeutic applications of the system for individuals with mood disorders or other emotional disturbances will also be explored. Overall, the proposed system has the potential to provide a more personalized and effective approach to music recommendation that takes into account the unique emotional responses of each individual user.
